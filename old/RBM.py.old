#!/usr/bin/python
import numpy as np
from scipy import optimize
import sys
'''
RBM	: Restricted Boltzman Machine.
Es un tipo de Red Neural Artificail (ANN) que desifra patrones por su cuenta sin supervision
'''
class RBM(object):
	def __init__(self, visibleSize=2, hiddenSize=3, Lambda=0):
		self.visibleLayerSize = visibleSize
		self.hiddenLayerSize = hiddenSize
		#weights = []
		#for i in xrange(hiddenSize):
		#	row = []
		#	for j in xrange(visibleSize):
		#		row.append(0.5)
		#	weights.append(np.array(row, dtype=float))
		#     
		#self.Weights = np.array(weights, dtype=float)
		self.Weights = np.random.randn(self.hiddenLayerSize, self.visibleLayerSize)
		C = []
		for n in xrange(self.visibleLayerSize):
			C.append(0.2)
		self.visibleBias = np.array(C, dtype=float)
		#self.visibleBias = np.random.randn(self.visibleLayerSize, 1)
		K = []
		for n in xrange(self.hiddenLayerSize):
			K.append(0.3)
		self.hiddenBias = np.array(K, dtype=float)
		#self.hiddenBias = np.random.randn(self.hiddenLayerSize, 1)
		self.Lambda = Lambda

	def forward(self, X):
		self.z2 = np.dot(X, self.Weights)
		yHat = self.sigmoid(self.z2)
		return yHat

	def sigmoid(self, z):
		return 1/(1+np.exp(-z))	

	def identity(self, z):
		return z

	def sigmoidPrime(self, z):
		return np.exp(-z)/((1+np.exp(-z))**2)

	def costFunction(self, X, y):
		self.yHat = self.forward(X)
		J = 0.5*np.sum((y-self.yHat)**2)/X.shape[0] + (self.Lambda/2)*(np.sum(self.Weights**2))
		return J

	def costFunctionPrime(self, X, y):
		self.yHat = self.forward(X)
		delta = np.multiply(-(y-self.yHat), self.sigmoidPrime(self.z2))
		djdW = np.dot(self.yHat.T, delta) + self.Lambda*self.Weights
		return djdW
	
	def getParams(self):
		params = self.Weights.ravel()
		return params

	def setParams(self, params):
		#W1_start = 0
		#W1_end = self.hiddenLayerSize*self.visibleLayerSize
		#self.Weights = np.reshape(params[W1_start:W1_end], (self.visibleLayerSize, self.hiddenLayerSize))
		self.Weights = np.reshape(params, (self.hiddenLayerSize, self.visibleLayerSize))

	def computeGradients(self, X, y):
		djdW = self.costFunctionPrime(X,y)
		return djdW.ravel()

	def hiddenProbability(self, V):	
		# Z = np.sum(np.dot(self.Weights, V))
		Z = np.dot(self.Weights, V)
		#Z = self.hiddenBias + Z
		return self.sigmoid(Z)#self.sigmoid(np.dot(self.Weights.T, V) + self.hiddenBias)

	def visibleProbability(self, H):
		# Z = np.sum(np.dot(self.Weights.T, H))
		Z = np.dot(H, self.Weights)
		#Z = self.visibleBias + Z
		#return True and self.sigmoid(Z) or Z
		#return self.bernoulli(self.sigmoid(Z))
		return self.sigmoid(Z)

	def check(self, X):
		H = self.hiddenProbability(X)
		return self.visibleProbability(H)

	def trainNetwork(self,V, dbh, batch_size=10):
		# 1. Set all the inputs to training values and get H.
		# print self.sigmoid(1.3)
		c = 0
		total = len(V)
		for v in V:
			c += 1
			print "Elemento",c,"de",total
			#v2 = (v - 1)**2
			for j in xrange(self.hiddenLayerSize):
				sumation1 = 0
				sumation2 = 0
				for i in xrange(self.visibleLayerSize):
					Pos = self.sigmoid( self.hiddenBias[j] + v[i]*self.Weights[j][i] )
					Neg = v[i]
					for _ in xrange(2):
						X = self.sigmoid( self.hiddenBias[j] + Neg*self.Weights[j][i] )
						Neg = self.sigmoid( self.visibleBias[i] + X*self.Weights[j][i] )
					self.Weights[j][i] = self.Weights[j][i] + 0.5*(Pos-Neg)
			#for _ in xrange(10):
			#	# Gibbs Sampling
			#	v2 = self.hiddenProbability(v2)
			#	v2 = self.bernoulli(self.visibleProbability(v2))
			# Negative Phase
			#H = self.hiddenProbability(v)
			#print "H", H
			#H2 = self.hiddenProbability(v2)
			# Positive Phase
			#netV1 = np.dot(v, np.dot(H, self.Weights)) + np.dot(v2, np.dot(H2, self.Weights)) + self.visibleBias
			#negative = self.sigmoid(netV1)
			#print negative
			#vP = self.visibleProbability(H)
			#vP2 = self.visibleProbability(H2)
			# Update Weights
			#print np.exp(-self.energyFunction(v, H))/self.partitionFunction(v,H)
			#correction = v - VP.T
			#print correction
			#self.Weights = self.Weights + 0.5*(vP - vP2)
			#print v
			if c%10==0:
				print "actualizando peso"
				upd = dbh.query("UPDATE weight SET weight=? WHERE layer='Layer One';",(self.getParams(),))
			#uns = dbh.query("INSERT INTO weight(weight, current, layer) VALUES(?,1,'Layer One')",(self.getParams(),))

	def energyFunction(self,V,H):
		'''
		E(H,V) = SUM(VisibleBiasVector * VisibleVector) - SUM(HiddenViasVector * HiddenVector) - SUM(VisibleVector*Weight*HiddenVector)
		'''
		return -np.sum(np.dot(V, (np.dot(H.T, self.Weights.T)))) -np.sum(np.dot(self.visibleBias.T, V)) - np.sum(np.dot(self.hiddenBias.T, H))


	def partitionFunction(self, V, H):
		'''
		Z = SUM(e^-E(v,h))
		'''
		return (np.expm1(-self.energyFunction(V,H)))

	def bernoulli(self,p):
		b = np.random.rand(*p.shape) < p
		return np.array(b, dtype=float)
